import os
import sys
import torch
import torch.nn as nn
from mmcv import Config
from mmcls.models import build_classifier
import numpy as np
from typing import Dict, Any, Tuple

import mmfscil


def count_parameters(model: nn.Module) -> Dict[str, int]:
    """λ¨λΈμ νλΌλ―Έν„° μλ¥Ό κ³„μ‚°ν•©λ‹λ‹¤."""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    frozen_params = total_params - trainable_params
    
    return {
        'total': total_params,
        'trainable': trainable_params,
        'frozen': frozen_params
    }




def try_thop_flops_component(component: nn.Module, input_shape: Tuple[int, ...], component_name: str) -> Tuple[int, int]:
    """μ»΄ν¬λ„νΈλ³„λ΅ thop λΌμ΄λΈλ¬λ¦¬λ¥Ό μ‚¬μ©ν•μ—¬ FLOPsλ¥Ό κ³„μ‚°ν•©λ‹λ‹¤."""
    try:
        from thop import profile
        
        # CUDA μ‚¬μ© κ°€λ¥ν•λ©΄ CUDAλ΅, μ•„λ‹λ©΄ CPUλ΅
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        component = component.to(device)
        component.eval()
        
        dummy_input = torch.randn(1, *input_shape).to(device)
        
        # ETFHeadμ κ²½μ° νΉλ³„ μ²λ¦¬
        if 'ETFHead' in component_name:
            # ETFHeadλ” forward λ€μ‹  simple_testλ‚ λ‹¤λ¥Έ λ©”μ„λ“λ¥Ό μ‚¬μ©ν•  μ μμ
            try:
                # λ¨Όμ € μΌλ°μ μΈ forward μ‹λ„
                flops, params = profile(component, inputs=(dummy_input,), verbose=False)
            except:
                # forwardκ°€ μ—†μΌλ©΄ νλΌλ―Έν„°λ§ κ³„μ‚°
                params = sum(p.numel() for p in component.parameters())
                # ETFHeadλ” μ£Όλ΅ Linear layerμ΄λ―€λ΅ κ°„λ‹¨ν μ¶”μ •
                if hasattr(component, 'in_channels') and hasattr(component, 'num_classes'):
                    flops = component.in_channels * component.num_classes
                else:
                    flops = 0
                print(f"    π’΅ ETFHeadλ” ν‘μ¤€ forwardκ°€ μ—†μ–΄ μ¶”μ •κ°’ μ‚¬μ©")
                return int(flops), int(params)
        else:
            # thopμ„ μ‚¬μ©ν•μ—¬ FLOPsμ™€ νλΌλ―Έν„° κ³„μ‚°
            flops, params = profile(component, inputs=(dummy_input,), verbose=False)
        
        return int(flops), int(params)
    except ImportError:
        print("π’΅ thop λΌμ΄λΈλ¬λ¦¬κ°€ μ„¤μΉλμ§€ μ•μ•μµλ‹λ‹¤. μ„¤μΉν•λ ¤λ©΄: pip install thop")
        return None, None
    except Exception as e:
        print(f"Warning: {component_name} thop FLOPs κ³„μ‚° μ¤‘ μ¤λ¥ λ°μƒ: {e}")
        # μµμ†ν• νλΌλ―Έν„° μλ” κ³„μ‚°
        try:
            params = sum(p.numel() for p in component.parameters())
            return 0, int(params)  # FLOPsλ” 0μΌλ΅, νλΌλ―Έν„°λ” μ‹¤μ  κ°’
        except:
            return None, None


def analyze_components_flops(model, input_shape: Tuple[int, ...] = (3, 224, 224)):
    """λ¨λΈμ κ° μ»΄ν¬λ„νΈλ³„λ΅ FLOPsλ¥Ό λ¶„μ„ν•©λ‹λ‹¤."""
    print(f"\nβ΅ μ»΄ν¬λ„νΈλ³„ FLOPs λ¶„μ„ (μ…λ ¥ ν¬κΈ°: {input_shape})")
    print("=" * 60)
    
    total_flops = 0
    total_params = 0
    
    # Backbone λ¶„μ„
    if hasattr(model, 'backbone') and model.backbone is not None:
        print(f"\nπ”§ Backbone: {type(model.backbone).__name__}")
        print("-" * 40)
        backbone_flops, thop_params = try_thop_flops_component(model.backbone, input_shape, "Backbone")
        # μ‹¤μ  νλΌλ―Έν„° μλ” μ§μ ‘ κ³„μ‚° (thopμ΄ λ†“μΉ  μ μμ)
        actual_params = sum(p.numel() for p in model.backbone.parameters())
        
        if backbone_flops is not None:
            print(f"  π“ FLOPs:      {format_number(backbone_flops):>12}")
            print(f"  π”Ά νλΌλ―Έν„°:    {format_number(actual_params):>12}")
            total_flops += backbone_flops
            total_params += actual_params
        else:
            print("  β FLOPs κ³„μ‚° μ‹¤ν¨")
            print(f"  π”Ά νλΌλ―Έν„°:    {format_number(actual_params):>12}")
            total_params += actual_params
        
        # Backbone μ¶λ ¥ ν¬κΈ° μ¶”μ • (μΌλ°μ μΌλ΅ 7x7 feature map)
        backbone_output_shape = (1024, 7, 7)  # VMamba baseμ μΌλ°μ μΈ μ¶λ ¥
    
    # Neck λ¶„μ„
    if hasattr(model, 'neck') and model.neck is not None:
        print(f"\nπ”— Neck: {type(model.neck).__name__}")
        print("-" * 40)
        try:
            # Neckμ€ backboneμ μ¶λ ¥μ„ μ…λ ¥μΌλ΅ λ°›μ
            neck_input_shape = backbone_output_shape
            neck_flops, thop_params = try_thop_flops_component(model.neck, neck_input_shape, "Neck")
            # μ‹¤μ  νλΌλ―Έν„° μλ” μ§μ ‘ κ³„μ‚° (thopμ΄ λ†“μΉ  μ μμ)
            actual_params = sum(p.numel() for p in model.neck.parameters())
            
            if neck_flops is not None:
                print(f"  π“ FLOPs:      {format_number(neck_flops):>12}")
                print(f"  π”Ά νλΌλ―Έν„°:    {format_number(actual_params):>12}")
                total_flops += neck_flops
                total_params += actual_params
            else:
                print("  β FLOPs κ³„μ‚° μ‹¤ν¨")
                print(f"  π”Ά νλΌλ―Έν„°:    {format_number(actual_params):>12}")
                total_params += actual_params
        except Exception as e:
            print(f"  β FLOPs κ³„μ‚° μ‹¤ν¨: {e}")
    
    # Head λ¶„μ„
    if hasattr(model, 'head') and model.head is not None:
        print(f"\nπ― Head: {type(model.head).__name__}")
        print("-" * 40)
        try:
            # Headλ” neckμ μ¶λ ¥μ„ μ…λ ¥μΌλ΅ λ°›μ (μΌλ°μ μΌλ΅ 1D feature)
            head_input_shape = (1024,)  # Neck μ¶λ ¥ μ°¨μ›
            head_flops, thop_params = try_thop_flops_component(model.head, head_input_shape, "Head")
            # μ‹¤μ  νλΌλ―Έν„° μλ” μ§μ ‘ κ³„μ‚° (thopμ΄ λ†“μΉ  μ μμ)
            actual_params = sum(p.numel() for p in model.head.parameters())
            
            if head_flops is not None:
                print(f"  π“ FLOPs:      {format_number(head_flops):>12}")
                print(f"  π”Ά νλΌλ―Έν„°:    {format_number(actual_params):>12}")
                total_flops += head_flops
                total_params += actual_params
            else:
                print("  β FLOPs κ³„μ‚° μ‹¤ν¨")
                print(f"  π”Ά νλΌλ―Έν„°:    {format_number(actual_params):>12}")
                total_params += actual_params
        except Exception as e:
            print(f"  β FLOPs κ³„μ‚° μ‹¤ν¨: {e}")
    
    if total_flops > 0:
        print(f"\nπ† μ „μ²΄ μ¶”μ •κ°’")
        print("=" * 40)
        print(f"  π“ μ΄ FLOPs:      {format_number(total_flops):>12}")
        print(f"  π”Ά μ΄ νλΌλ―Έν„°:    {format_number(total_params):>12}")
    
    return total_flops, total_params


def format_number(num: int) -> str:
    """μ«μλ¥Ό μ½κΈ° μ‰¬μ΄ ν•νƒλ΅ ν¬λ§·ν•©λ‹λ‹¤."""
    if num >= 1e12:
        return f"{num/1e12:.2f}T"
    elif num >= 1e9:
        return f"{num/1e9:.2f}G"
    elif num >= 1e6:
        return f"{num/1e6:.2f}M"
    elif num >= 1e3:
        return f"{num/1e3:.2f}K"
    else:
        return str(num)


def analyze_model_components(model: nn.Module) -> Dict[str, Dict[str, int]]:
    """λ¨λΈμ κ° μ»΄ν¬λ„νΈλ³„ νλΌλ―Έν„° μλ¥Ό λ¶„μ„ν•©λ‹λ‹¤."""
    component_stats = {}
    
    for name, module in model.named_children():
        params = count_parameters(module)
        component_stats[name] = params
    
    return component_stats


def print_model_analysis(model: nn.Module, config_name: str, input_shape: Tuple[int, ...] = (3, 224, 224)):
    """λ¨λΈ λ¶„μ„ κ²°κ³Όλ¥Ό μ¶λ ¥ν•©λ‹λ‹¤."""
    print("=" * 80)
    print(f"π” CUB λ¨λΈ λ¶„μ„ κ²°κ³Ό - {config_name}")
    print("=" * 80)
    
    # νλΌλ―Έν„° μ κ³„μ‚°
    param_stats = count_parameters(model)
    print(f"\nπ“ νλΌλ―Έν„° ν†µκ³„:")
    print("-" * 50)
    print(f"  μ „μ²΄ νλΌλ―Έν„°:     {format_number(param_stats['total']):>12} ({param_stats['total']:,})")
    print(f"  ν›λ ¨ κ°€λ¥:        {format_number(param_stats['trainable']):>12} ({param_stats['trainable']:,})")
    print(f"  κ³ μ •λ¨:          {format_number(param_stats['frozen']):>12} ({param_stats['frozen']:,})")
    
    # μ»΄ν¬λ„νΈλ³„ λ¶„μ„
    print(f"\nπ§© μ»΄ν¬λ„νΈλ³„ νλΌλ―Έν„°:")
    print("-" * 50)
    component_stats = analyze_model_components(model)
    for comp_name, stats in component_stats.items():
        print(f"  {comp_name:12}: {format_number(stats['total']):>12} ({stats['total']:,})")
    
    # μ»΄ν¬λ„νΈλ³„ FLOPs λ¶„μ„
    analyze_components_flops(model, input_shape)


def main():
    print("π€ CUB λ¨λΈ λ¶„μ„μ„ μ‹μ‘ν•©λ‹λ‹¤...")
    print("=" * 80)
    
    # CUB μ„¤μ • νμΌλ“¤
    configs = {
        "CUB Base": "configs/cub/cub_base.py",
        "CUB Incremental": "configs/cub/cub_inc.py"
    }
    
    # CUB μ΄λ―Έμ§€ ν¬κΈ° (μΌλ°μ μΌλ΅ 224x224)
    input_shape = (3, 224, 224)
    
    for config_name, config_path in configs.items():
        if not os.path.exists(config_path):
            print(f"\nβ μ„¤μ • νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {config_path}")
            continue
            
        try:
            print(f"\nπ”„ {config_name} λ¨λΈ λ΅λ”© μ¤‘...")
            print("-" * 40)
            
            # μ„¤μ • νμΌ λ΅λ“
            cfg = Config.fromfile(config_path)
            
            # λ¨λΈ λΉλ“
            model = build_classifier(cfg.model)
            
            # λ¨λΈ λ¶„μ„ μ‹¤ν–‰
            print_model_analysis(model, config_name, input_shape)
            
        except Exception as e:
            print(f"\nβ {config_name} λ¨λΈ λ¶„μ„ μ¤‘ μ¤λ¥ λ°μƒ: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    print("β… λ¨λΈ λ¶„μ„μ΄ μ™„λ£λμ—μµλ‹λ‹¤!")

if __name__ == '__main__':
    main()
