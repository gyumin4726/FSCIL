import os
import sys
import torch
import torch.nn as nn
from mmcv import Config
from mmcls.models import build_classifier
import numpy as np
from typing import Dict, Any, Tuple

import mmfscil


def count_parameters(model: nn.Module) -> Dict[str, int]:
    """ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    frozen_params = total_params - trainable_params
    
    return {
        'total': total_params,
        'trainable': trainable_params,
        'frozen': frozen_params
    }




def try_thop_flops_component(component: nn.Module, input_shape: Tuple[int, ...], component_name: str) -> Tuple[int, int]:
    """ì»´í¬ë„ŒíŠ¸ë³„ë¡œ thop ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ FLOPsë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    try:
        from thop import profile
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ CUDAë¡œ, ì•„ë‹ˆë©´ CPUë¡œ
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        component = component.to(device)
        component.eval()
        
        dummy_input = torch.randn(1, *input_shape).to(device)
        
        # ETFHeadì˜ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
        if 'ETFHead' in component_name:
            # ETFHeadëŠ” forward ëŒ€ì‹  simple_testë‚˜ ë‹¤ë¥¸ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
            try:
                # ë¨¼ì € ì¼ë°˜ì ì¸ forward ì‹œë„
                flops, params = profile(component, inputs=(dummy_input,), verbose=False)
            except:
                # forwardê°€ ì—†ìœ¼ë©´ íŒŒë¼ë¯¸í„°ë§Œ ê³„ì‚°
                params = sum(p.numel() for p in component.parameters())
                # ETFHeadëŠ” ì£¼ë¡œ Linear layerì´ë¯€ë¡œ ê°„ë‹¨íˆ ì¶”ì •
                if hasattr(component, 'in_channels') and hasattr(component, 'num_classes'):
                    flops = component.in_channels * component.num_classes
                else:
                    flops = 0
                print(f"    ğŸ’¡ ETFHeadëŠ” í‘œì¤€ forwardê°€ ì—†ì–´ ì¶”ì •ê°’ ì‚¬ìš©")
                return int(flops), int(params)
        else:
            # thopì„ ì‚¬ìš©í•˜ì—¬ FLOPsì™€ íŒŒë¼ë¯¸í„° ê³„ì‚°
            flops, params = profile(component, inputs=(dummy_input,), verbose=False)
        
        return int(flops), int(params)
    except ImportError:
        print("ğŸ’¡ thop ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install thop")
        return None, None
    except Exception as e:
        print(f"Warning: {component_name} thop FLOPs ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ìµœì†Œí•œ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ê³„ì‚°
        try:
            params = sum(p.numel() for p in component.parameters())
            return 0, int(params)  # FLOPsëŠ” 0ìœ¼ë¡œ, íŒŒë¼ë¯¸í„°ëŠ” ì‹¤ì œ ê°’
        except:
            return None, None


def analyze_components_flops(model, input_shape: Tuple[int, ...] = (3, 224, 224)):
    """ëª¨ë¸ì˜ ê° ì»´í¬ë„ŒíŠ¸ë³„ë¡œ FLOPsë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    print(f"\nâš¡ ì»´í¬ë„ŒíŠ¸ë³„ FLOPs ë¶„ì„ (ì…ë ¥ í¬ê¸°: {input_shape})")
    print("=" * 60)
    
    total_flops = 0
    total_params = 0
    
    # Backbone ë¶„ì„
    if hasattr(model, 'backbone') and model.backbone is not None:
        print(f"\nğŸ”§ Backbone: {type(model.backbone).__name__}")
        print("-" * 40)
        backbone_flops, thop_params = try_thop_flops_component(model.backbone, input_shape, "Backbone")
        # ì‹¤ì œ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ì§ì ‘ ê³„ì‚° (thopì´ ë†“ì¹  ìˆ˜ ìˆìŒ)
        actual_params = sum(p.numel() for p in model.backbone.parameters())
        
        if backbone_flops is not None:
            print(f"  ğŸ“Š FLOPs:      {format_number(backbone_flops):>12}")
            print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:    {format_number(actual_params):>12}")
            total_flops += backbone_flops
            total_params += actual_params
        else:
            print("  âŒ FLOPs ê³„ì‚° ì‹¤íŒ¨")
            print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:    {format_number(actual_params):>12}")
            total_params += actual_params
        
        # Backbone ì¶œë ¥ í¬ê¸° ìë™ ê°ì§€
        try:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            with torch.no_grad():
                dummy_input = torch.randn(1, *input_shape).to(device)
                model.backbone.eval()
                backbone_out = model.backbone(dummy_input)
                if isinstance(backbone_out, tuple):
                    backbone_out = backbone_out[-1]  # ë§ˆì§€ë§‰ feature map ì‚¬ìš©
                _, C, H, W = backbone_out.shape
                backbone_output_shape = (C, H, W)
                print(f"  âœ… Backbone ì¶œë ¥ í¬ê¸°: {backbone_output_shape}")
        except Exception as e:
            # ì‹¤íŒ¨í•˜ë©´ neckì˜ in_channels ì‚¬ìš©
            if hasattr(model.neck, 'in_channels'):
                backbone_output_shape = (model.neck.in_channels, 7, 7)
                print(f"  ğŸ’¡ Neckì˜ in_channelsë¡œë¶€í„° ì¶”ì •: {backbone_output_shape}")
            else:
                backbone_output_shape = (1024, 7, 7)  # ê¸°ë³¸ê°’
                print(f"  âš ï¸ ê¸°ë³¸ê°’ ì‚¬ìš©: {backbone_output_shape}")
    
    # Neck ë¶„ì„
    if hasattr(model, 'neck') and model.neck is not None:
        print(f"\nğŸ”— Neck: {type(model.neck).__name__}")
        print("-" * 40)
        try:
            # Neckì€ backboneì˜ ì¶œë ¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ
            neck_input_shape = backbone_output_shape
            neck_flops, thop_params = try_thop_flops_component(model.neck, neck_input_shape, "Neck")
            # ì‹¤ì œ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ì§ì ‘ ê³„ì‚° (thopì´ ë†“ì¹  ìˆ˜ ìˆìŒ)
            actual_params = sum(p.numel() for p in model.neck.parameters())
            
            if neck_flops is not None:
                print(f"  ğŸ“Š FLOPs:      {format_number(neck_flops):>12}")
                print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:    {format_number(actual_params):>12}")
                total_flops += neck_flops
                total_params += actual_params
            else:
                print("  âŒ FLOPs ê³„ì‚° ì‹¤íŒ¨")
                print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:    {format_number(actual_params):>12}")
                total_params += actual_params
        except Exception as e:
            print(f"  âŒ FLOPs ê³„ì‚° ì‹¤íŒ¨: {e}")
    
    # Head ë¶„ì„
    if hasattr(model, 'head') and model.head is not None:
        print(f"\nğŸ¯ Head: {type(model.head).__name__}")
        print("-" * 40)
        try:
            # HeadëŠ” neckì˜ ì¶œë ¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ (ì¼ë°˜ì ìœ¼ë¡œ 1D feature)
            # neckì˜ out_channels ë˜ëŠ” headì˜ in_channels ì‚¬ìš©
            if hasattr(model.neck, 'out_channels'):
                head_input_dim = model.neck.out_channels
            elif hasattr(model.head, 'in_channels'):
                head_input_dim = model.head.in_channels
            else:
                head_input_dim = 1024  # ê¸°ë³¸ê°’
            head_input_shape = (head_input_dim,)  # Neck ì¶œë ¥ ì°¨ì›
            head_flops, thop_params = try_thop_flops_component(model.head, head_input_shape, "Head")
            # ì‹¤ì œ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ì§ì ‘ ê³„ì‚° (thopì´ ë†“ì¹  ìˆ˜ ìˆìŒ)
            actual_params = sum(p.numel() for p in model.head.parameters())
            
            if head_flops is not None:
                print(f"  ğŸ“Š FLOPs:      {format_number(head_flops):>12}")
                print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:    {format_number(actual_params):>12}")
                total_flops += head_flops
                total_params += actual_params
            else:
                print("  âŒ FLOPs ê³„ì‚° ì‹¤íŒ¨")
                print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:    {format_number(actual_params):>12}")
                total_params += actual_params
        except Exception as e:
            print(f"  âŒ FLOPs ê³„ì‚° ì‹¤íŒ¨: {e}")
    
    if total_flops > 0:
        print(f"\nğŸ† ì „ì²´ ì¶”ì •ê°’")
        print("=" * 40)
        print(f"  ğŸ“Š ì´ FLOPs:      {format_number(total_flops):>12}")
        print(f"  ğŸ”¢ ì´ íŒŒë¼ë¯¸í„°:    {format_number(total_params):>12}")
    
    return total_flops, total_params


def format_number(num: int) -> str:
    """ìˆ«ìë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·í•©ë‹ˆë‹¤."""
    if num >= 1e12:
        return f"{num/1e12:.2f}T"
    elif num >= 1e9:
        return f"{num/1e9:.2f}G"
    elif num >= 1e6:
        return f"{num/1e6:.2f}M"
    elif num >= 1e3:
        return f"{num/1e3:.2f}K"
    else:
        return str(num)


def analyze_model_components(model: nn.Module) -> Dict[str, Dict[str, int]]:
    """ëª¨ë¸ì˜ ê° ì»´í¬ë„ŒíŠ¸ë³„ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    component_stats = {}
    
    for name, module in model.named_children():
        params = count_parameters(module)
        component_stats[name] = params
    
    return component_stats


def print_model_analysis(model: nn.Module, config_name: str, input_shape: Tuple[int, ...] = (3, 224, 224)):
    """ëª¨ë¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("=" * 80)
    print(f"ğŸ” CUB ëª¨ë¸ ë¶„ì„ ê²°ê³¼ - {config_name}")
    print("=" * 80)
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    param_stats = count_parameters(model)
    print(f"\nğŸ“Š íŒŒë¼ë¯¸í„° í†µê³„:")
    print("-" * 50)
    print(f"  ì „ì²´ íŒŒë¼ë¯¸í„°:     {format_number(param_stats['total']):>12} ({param_stats['total']:,})")
    print(f"  í›ˆë ¨ ê°€ëŠ¥:        {format_number(param_stats['trainable']):>12} ({param_stats['trainable']:,})")
    print(f"  ê³ ì •ë¨:          {format_number(param_stats['frozen']):>12} ({param_stats['frozen']:,})")
    
    # ì»´í¬ë„ŒíŠ¸ë³„ ë¶„ì„
    print(f"\nğŸ§© ì»´í¬ë„ŒíŠ¸ë³„ íŒŒë¼ë¯¸í„°:")
    print("-" * 50)
    component_stats = analyze_model_components(model)
    for comp_name, stats in component_stats.items():
        print(f"  {comp_name:12}: {format_number(stats['total']):>12} ({stats['total']:,})")
    
    # ì»´í¬ë„ŒíŠ¸ë³„ FLOPs ë¶„ì„
    analyze_components_flops(model, input_shape)


def main():
    print("ğŸš€ CUB ëª¨ë¸ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("=" * 80)
    
    # CUB ì„¤ì • íŒŒì¼ë“¤
    configs = {
        "CUB Base": "configs/cub/cub_base.py",
        "CUB Incremental": "configs/cub/cub_inc.py"
    }
    
    # CUB ì´ë¯¸ì§€ í¬ê¸° (ì¼ë°˜ì ìœ¼ë¡œ 224x224)
    input_shape = (3, 224, 224)
    
    for config_name, config_path in configs.items():
        if not os.path.exists(config_path):
            print(f"\nâŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            continue
            
        try:
            print(f"\nğŸ”„ {config_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
            print("-" * 40)
            
            # ì„¤ì • íŒŒì¼ ë¡œë“œ
            cfg = Config.fromfile(config_path)
            
            # ëª¨ë¸ ë¹Œë“œ
            model = build_classifier(cfg.model)
            
            # ëª¨ë¸ ë¶„ì„ ì‹¤í–‰
            print_model_analysis(model, config_name, input_shape)
            
        except Exception as e:
            print(f"\nâŒ {config_name} ëª¨ë¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    print("âœ… ëª¨ë¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == '__main__':
    main()
