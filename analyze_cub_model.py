import os
import sys
import torch
import torch.nn as nn
from mmcv import Config
from mmcls.models import build_classifier
import numpy as np
from typing import Dict, Any, Tuple

import mmfscil


def count_parameters(model: nn.Module) -> Dict[str, int]:
    """ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    frozen_params = total_params - trainable_params
    
    return {
        'total': total_params,
        'trainable': trainable_params,
        'frozen': frozen_params
    }




def try_thop_flops_component(component: nn.Module, input_shape: Tuple[int, ...], component_name: str) -> Tuple[int, int]:
    """ì»´í¬ë„ŒíŠ¸ë³„ë¡œ thop ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ FLOPsë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    try:
        from thop import profile
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ CUDAë¡œ, ì•„ë‹ˆë©´ CPUë¡œ
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        component = component.to(device)
        component.eval()
        
        dummy_input = torch.randn(1, *input_shape).to(device)
        
        # ETFHeadì˜ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
        if 'ETFHead' in component_name:
            # ETFHeadëŠ” forward ëŒ€ì‹  simple_testë‚˜ ë‹¤ë¥¸ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
            try:
                # ë¨¼ì € ì¼ë°˜ì ì¸ forward ì‹œë„
                flops, params = profile(component, inputs=(dummy_input,), verbose=False)
            except:
                # forwardê°€ ì—†ìœ¼ë©´ íŒŒë¼ë¯¸í„°ë§Œ ê³„ì‚°
                params = sum(p.numel() for p in component.parameters())
                # ETFHeadëŠ” ì£¼ë¡œ Linear layerì´ë¯€ë¡œ ê°„ë‹¨íˆ ì¶”ì •
                if hasattr(component, 'in_channels') and hasattr(component, 'num_classes'):
                    flops = component.in_channels * component.num_classes
                else:
                    flops = 0
                print(f"    ğŸ’¡ ETFHeadëŠ” í‘œì¤€ forwardê°€ ì—†ì–´ ì¶”ì •ê°’ ì‚¬ìš©")
                return int(flops), int(params)
        else:
            # thopì„ ì‚¬ìš©í•˜ì—¬ FLOPsì™€ íŒŒë¼ë¯¸í„° ê³„ì‚°
            flops, params = profile(component, inputs=(dummy_input,), verbose=False)
        
        return int(flops), int(params)
    except ImportError:
        print("ğŸ’¡ thop ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install thop")
        return None, None
    except Exception as e:
        print(f"Warning: {component_name} thop FLOPs ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ìµœì†Œí•œ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ê³„ì‚°
        try:
            params = sum(p.numel() for p in component.parameters())
            return 0, int(params)  # FLOPsëŠ” 0ìœ¼ë¡œ, íŒŒë¼ë¯¸í„°ëŠ” ì‹¤ì œ ê°’
        except:
            return None, None


def analyze_moe_flops(neck: nn.Module, input_shape: Tuple[int, ...]) -> Dict[str, int]:
    """MoE Neckì˜ Train/Eval ëª¨ë“œë³„ FLOPsë¥¼ ì¶”ì •í•©ë‹ˆë‹¤."""
    flops_info = {
        'router': 0,
        'single_expert': 0,
        'train': 0,
        'eval': 0
    }
    
    if not hasattr(neck, 'moe'):
        return flops_info
    
    moe = neck.moe
    
    # Router FLOPs ì¶”ì • (Self-Attention + Cross-Attention + Projection)
    # ì…ë ¥: [B, H*W, dim]
    B = 1
    H, W = 7, 7  # ì¼ë°˜ì ì¸ feature map í¬ê¸°
    seq_len = H * W
    dim = getattr(moe, 'dim', 1024)
    num_heads = 8
    num_experts = getattr(moe, 'num_experts', 4)
    
    # Self-Attention FLOPs: Q, K, V projections + attention + output projection
    # QKV projection: 3 * (seq_len * dim * dim)
    # Attention: seq_len * seq_len * dim
    # Output projection: seq_len * dim * dim
    self_attn_flops = 3 * seq_len * dim * dim + seq_len * seq_len * dim + seq_len * dim * dim
    
    # Cross-Attention FLOPs (Query=features, Key&Value=expert_queries)
    # Q projection: seq_len * dim * dim
    # K, V projections: num_experts * dim * dim
    # Attention: seq_len * num_experts * dim
    # Output projection: seq_len * dim * dim
    cross_attn_flops = seq_len * dim * dim + 2 * num_experts * dim * dim + seq_len * num_experts * dim + seq_len * dim * dim
    
    # Gate projection: num_experts * dim
    gate_proj_flops = num_experts * dim
    
    flops_info['router'] = self_attn_flops + cross_attn_flops + gate_proj_flops
    
    # Single Expert FLOPs ì¶”ì • (SS2DëŠ” ë§¤ìš° ë³µì¡í•¨)
    if hasattr(moe, 'experts') and len(moe.experts) > 0:
        expert = moe.experts[0]
        if hasattr(expert, 'ss2d_block'):
            ss2d = expert.ss2d_block
            
            # SS2D íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            d_model = dim
            ssm_ratio = getattr(ss2d, 'ssm_ratio', 2.0) if hasattr(ss2d, 'ssm_ratio') else 2.0
            d_expand = int(ssm_ratio * d_model)
            d_state = getattr(ss2d, 'd_state', 16) if hasattr(ss2d, 'd_state') else 16
            dt_rank = getattr(ss2d, 'dt_rank', d_model // 16) if hasattr(ss2d, 'dt_rank') else d_model // 16
            K = getattr(ss2d, 'K', 4) if hasattr(ss2d, 'K') else 4  # ë°©í–¥ ê°œìˆ˜ (h, h_flip, v, v_flip)
            d_conv = getattr(ss2d, 'd_conv', 3) if hasattr(ss2d, 'd_conv') else 3
            
            seq_len = H * W
            
            # 1. Input projection: d_model â†’ 2*d_expand
            in_proj_flops = seq_len * d_model * (2 * d_expand)
            
            # 2. Convolution (depthwise): d_expand channels, kernel_size=d_conv
            if d_conv > 1:
                conv_flops = seq_len * d_expand * (d_conv * d_conv)
            else:
                conv_flops = 0
            
            # 3. x_proj: d_inner â†’ (dt_rank + d_state*2) for K directions
            d_inner = d_expand  # low rankì¸ ê²½ìš° ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
            x_proj_output_dim = dt_rank + d_state * 2
            x_proj_flops = K * seq_len * d_inner * x_proj_output_dim
            
            # 4. dt_proj: dt_rank â†’ d_inner for K directions
            dt_proj_flops = K * seq_len * dt_rank * d_inner
            
            # 5. Selective Scan (ê°€ì¥ ë³µì¡í•œ ë¶€ë¶„!)
            # ê° ë°©í–¥ë§ˆë‹¤ sequenceë¥¼ ë”°ë¼ state update ìˆ˜í–‰
            # State update: d_inner * d_state * seq_len (per direction)
            # Total for K directions
            selective_scan_flops = K * d_inner * d_state * seq_len * 6  # ëŒ€ëµì  ì—°ì‚° ë³µì¡ë„
            
            # 6. Output projection (if used): d_expand â†’ d_model
            out_proj_flops = seq_len * d_expand * d_model if getattr(ss2d, 'use_out_proj', True) else 0
            
            # 7. Layer Norm
            layer_norm_flops = seq_len * d_inner * 2
            
            # 8. Average Pooling (Expertì˜ ë§ˆì§€ë§‰)
            avg_pool_flops = H * W * dim
            
            # ì´í•©
            expert_flops = (in_proj_flops + conv_flops + x_proj_flops + dt_proj_flops + 
                          selective_scan_flops + out_proj_flops + layer_norm_flops + avg_pool_flops)
            
            flops_info['single_expert'] = expert_flops
            
            # ë””ë²„ê¹…ìš© ì„¸ë¶€ ì •ë³´ ì €ì¥
            flops_info['expert_details'] = {
                'in_proj': in_proj_flops,
                'conv': conv_flops,
                'x_proj': x_proj_flops,
                'dt_proj': dt_proj_flops,
                'selective_scan': selective_scan_flops,
                'out_proj': out_proj_flops,
                'layer_norm': layer_norm_flops,
                'avg_pool': avg_pool_flops
            }
        else:
            # SS2Dê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶”ì •
            expert_flops = dim * H * W * 100
            flops_info['single_expert'] = expert_flops
    
    # Train/Eval FLOPs
    train_top_k = getattr(moe, 'top_k', 2)
    eval_top_k = getattr(moe, 'eval_top_k', 1)
    
    flops_info['train'] = flops_info['router'] + flops_info['single_expert'] * train_top_k
    flops_info['eval'] = flops_info['router'] + flops_info['single_expert'] * eval_top_k
    
    return flops_info


def analyze_components_flops(model, input_shape: Tuple[int, ...] = (3, 224, 224)):
    """ëª¨ë¸ì˜ ê° ì»´í¬ë„ŒíŠ¸ë³„ë¡œ FLOPsë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    print(f"\nâš¡ ì»´í¬ë„ŒíŠ¸ë³„ FLOPs ë¶„ì„ (ì…ë ¥ í¬ê¸°: {input_shape})")
    print("=" * 60)
    
    total_flops = 0
    total_params = 0
    neck_train_flops = 0
    neck_eval_flops = 0
    
    # Backbone ë¶„ì„ (FLOPs ê³„ì‚°ì€ ìƒëµ, Neck ì…ë ¥ í¬ê¸°ë§Œ í™•ì¸)
    backbone_output_shape = (1024, 7, 7)  # ê¸°ë³¸ê°’
    
    if hasattr(model, 'backbone') and model.backbone is not None:
        print(f"\nğŸ”§ Backbone: {type(model.backbone).__name__}")
        print("-" * 40)
        
        actual_params = sum(p.numel() for p in model.backbone.parameters())
        print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:    {format_number(actual_params):>12}")
        print(f"  ğŸ’¡ FLOPs ê³„ì‚°ì€ ìƒëµí•©ë‹ˆë‹¤ (ë³µì¡í•œ êµ¬ì¡°)")
        total_params += actual_params
        
        # Backbone ì¶œë ¥ í¬ê¸° ìë™ ê°ì§€ (Neck ì…ë ¥ìš©)
        try:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            with torch.no_grad():
                dummy_input = torch.randn(1, *input_shape).to(device)
                model.backbone.eval()
                backbone_out = model.backbone(dummy_input)
                if isinstance(backbone_out, tuple):
                    backbone_out = backbone_out[-1]  # ë§ˆì§€ë§‰ feature map ì‚¬ìš©
                _, C, H, W = backbone_out.shape
                backbone_output_shape = (C, H, W)
                print(f"  âœ… Neck ì…ë ¥ í¬ê¸°: {backbone_output_shape}")
        except Exception as e:
            # ì‹¤íŒ¨í•˜ë©´ neckì˜ in_channels ì‚¬ìš©
            if hasattr(model, 'neck') and hasattr(model.neck, 'in_channels'):
                backbone_output_shape = (model.neck.in_channels, 7, 7)
                print(f"  ğŸ’¡ Neck ì…ë ¥ í¬ê¸° (ì¶”ì •): {backbone_output_shape}")
            else:
                print(f"  âš ï¸ Neck ì…ë ¥ í¬ê¸° (ê¸°ë³¸ê°’): {backbone_output_shape}")
    
    # Neck ë¶„ì„ (MoEëŠ” íŠ¹ë³„ ì²˜ë¦¬)
    if hasattr(model, 'neck') and model.neck is not None:
        print(f"\nğŸ”— Neck: {type(model.neck).__name__}")
        print("-" * 40)
        try:
            actual_params = sum(p.numel() for p in model.neck.parameters())
            
            # MoE Neckì¸ ê²½ìš° Train/Eval ë³„ë„ FLOPs ê³„ì‚°
            if 'MoE' in type(model.neck).__name__:
                print(f"  ğŸ’¡ MoE Neckì€ Train/Eval ëª¨ë“œë³„ë¡œ FLOPsê°€ ë‹¤ë¦…ë‹ˆë‹¤")
                moe_flops = analyze_moe_flops(model.neck, backbone_output_shape)
                
                print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:         {format_number(actual_params):>12}")
                print(f"\n  ğŸ“Š Router FLOPs:     {format_number(moe_flops['router']):>12}")
                print(f"  ğŸ“Š Single Expert:    {format_number(moe_flops['single_expert']):>12}")
                
                # Expert ì„¸ë¶€ FLOPs ì¶œë ¥ (ìˆëŠ” ê²½ìš°)
                if 'expert_details' in moe_flops:
                    details = moe_flops['expert_details']
                    print(f"     â”œâ”€ Input Proj:       {format_number(details['in_proj']):>10}")
                    print(f"     â”œâ”€ Conv2D:           {format_number(details['conv']):>10}")
                    print(f"     â”œâ”€ X Projection:     {format_number(details['x_proj']):>10}")
                    print(f"     â”œâ”€ DT Projection:    {format_number(details['dt_proj']):>10}")
                    print(f"     â”œâ”€ Selective Scan:   {format_number(details['selective_scan']):>10} ğŸ‘ˆ í•µì‹¬!")
                    print(f"     â”œâ”€ Output Proj:      {format_number(details['out_proj']):>10}")
                    print(f"     â”œâ”€ Layer Norm:       {format_number(details['layer_norm']):>10}")
                    print(f"     â””â”€ Avg Pool:         {format_number(details['avg_pool']):>10}")
                
                print(f"\n  âš¡ Train FLOPs:      {format_number(moe_flops['train']):>12} (top-k experts)")
                print(f"  âš¡ Eval FLOPs:       {format_number(moe_flops['eval']):>12} (top-k experts)")
                
                neck_train_flops = moe_flops['train']
                neck_eval_flops = moe_flops['eval']
                total_params += actual_params
            else:
                # ì¼ë°˜ Neck
                neck_input_shape = backbone_output_shape
                neck_flops, thop_params = try_thop_flops_component(model.neck, neck_input_shape, "Neck")
                
                if neck_flops is not None:
                    print(f"  ğŸ“Š FLOPs:      {format_number(neck_flops):>12}")
                    print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:    {format_number(actual_params):>12}")
                    total_flops += neck_flops
                    total_params += actual_params
                    neck_train_flops = neck_eval_flops = neck_flops
                else:
                    print("  âŒ FLOPs ê³„ì‚° ì‹¤íŒ¨")
                    print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:    {format_number(actual_params):>12}")
                    total_params += actual_params
        except Exception as e:
            print(f"  âŒ FLOPs ê³„ì‚° ì‹¤íŒ¨: {e}")
    
    # Head ë¶„ì„ (ETFHeadëŠ” íŒŒë¼ë¯¸í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ìƒëµ)
    # ETFHeadëŠ” ê³ ì •ëœ ETF classifierë¡œ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ê°€ ì—†ìŒ

    if neck_train_flops > 0:
        print(f"\nğŸ† Neck FLOPs ìš”ì•½")
        print("=" * 60)
        
        print(f"  ğŸ“Š Train FLOPs (Neck): {format_number(neck_train_flops):>12}")
        print(f"  ğŸ“Š Eval FLOPs (Neck):  {format_number(neck_eval_flops):>12}")
        
        flops_reduction = neck_train_flops - neck_eval_flops
        reduction_ratio = (flops_reduction / neck_train_flops * 100) if neck_train_flops > 0 else 0
        print(f"\n  ğŸ’¡ Eval FLOPs ì ˆê°:   {format_number(flops_reduction):>12} ({reduction_ratio:.1f}% ê°ì†Œ)")
        print(f"  ğŸ”¢ ì´ íŒŒë¼ë¯¸í„°:        {format_number(total_params):>12}")
    
    return total_flops, total_params


def format_number(num: int) -> str:
    """ìˆ«ìë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·í•©ë‹ˆë‹¤."""
    if num >= 1e12:
        return f"{num/1e12:.2f}T"
    elif num >= 1e9:
        return f"{num/1e9:.2f}G"
    elif num >= 1e6:
        return f"{num/1e6:.2f}M"
    elif num >= 1e3:
        return f"{num/1e3:.2f}K"
    else:
        return str(num)


def analyze_model_components(model: nn.Module) -> Dict[str, Dict[str, int]]:
    """ëª¨ë¸ì˜ ê° ì»´í¬ë„ŒíŠ¸ë³„ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    component_stats = {}
    
    for name, module in model.named_children():
        params = count_parameters(module)
        component_stats[name] = params
    
    return component_stats


def analyze_moe_neck(neck: nn.Module) -> Dict[str, Any]:
    """MoE Neckì˜ ì„¸ë¶€ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    stats = {
        'total_params': sum(p.numel() for p in neck.parameters()),
        'components': {}
    }
    
    # MoE ëª¨ë“ˆ ë¶„ì„
    if hasattr(neck, 'moe'):
        moe = neck.moe
        
        # Gate (Router) ë¶„ì„
        if hasattr(moe, 'gate'):
            gate_params = sum(p.numel() for p in moe.gate.parameters())
            stats['components']['gate_router'] = gate_params
            
            # Gate ë‚´ë¶€ ì„¸ë¶€ ë¶„ì„
            gate_details = {}
            if hasattr(moe.gate, 'spatial_self_attention'):
                gate_details['self_attention'] = sum(p.numel() for p in moe.gate.spatial_self_attention.parameters())
            if hasattr(moe.gate, 'expert_cross_attention'):
                gate_details['cross_attention'] = sum(p.numel() for p in moe.gate.expert_cross_attention.parameters())
            if hasattr(moe.gate, 'expert_queries'):
                gate_details['expert_queries'] = moe.gate.expert_queries.numel()
            if hasattr(moe.gate, 'gate_proj'):
                gate_details['gate_proj'] = sum(p.numel() for p in moe.gate.gate_proj.parameters())
            
            stats['components']['gate_details'] = gate_details
        
        # Experts ë¶„ì„
        if hasattr(moe, 'experts'):
            experts = moe.experts
            num_experts = len(experts)
            single_expert_params = sum(p.numel() for p in experts[0].parameters()) if num_experts > 0 else 0
            total_experts_params = sum(p.numel() for p in experts.parameters())
            
            stats['components']['experts'] = {
                'num_experts': num_experts,
                'single_expert': single_expert_params,
                'total_experts': total_experts_params
            }
            
            # Top-K ì •ë³´
            if hasattr(moe, 'top_k') and hasattr(moe, 'eval_top_k'):
                stats['top_k_info'] = {
                    'train_top_k': moe.top_k,
                    'eval_top_k': moe.eval_top_k,
                    'train_activation_ratio': moe.top_k / num_experts,
                    'eval_activation_ratio': moe.eval_top_k / num_experts
                }
    
    # Position embedding
    if hasattr(neck, 'pos_embed'):
        stats['components']['pos_embed'] = neck.pos_embed.numel()
    
    return stats


def print_model_analysis(model: nn.Module, config_name: str, input_shape: Tuple[int, ...] = (3, 224, 224)):
    """ëª¨ë¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("=" * 80)
    print(f"ğŸ” CUB ëª¨ë¸ ë¶„ì„ ê²°ê³¼ - {config_name}")
    print("=" * 80)
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    param_stats = count_parameters(model)
    print(f"\nğŸ“Š íŒŒë¼ë¯¸í„° í†µê³„:")
    print("-" * 50)
    print(f"  ì „ì²´ íŒŒë¼ë¯¸í„°:     {format_number(param_stats['total']):>12} ({param_stats['total']:,})")
    print(f"  í›ˆë ¨ ê°€ëŠ¥:        {format_number(param_stats['trainable']):>12} ({param_stats['trainable']:,})")
    print(f"  ê³ ì •ë¨:          {format_number(param_stats['frozen']):>12} ({param_stats['frozen']:,})")
    
    # ì»´í¬ë„ŒíŠ¸ë³„ ë¶„ì„
    print(f"\nğŸ§© ì»´í¬ë„ŒíŠ¸ë³„ íŒŒë¼ë¯¸í„°:")
    print("-" * 50)
    component_stats = analyze_model_components(model)
    for comp_name, stats in component_stats.items():
        print(f"  {comp_name:12}: {format_number(stats['total']):>12} ({stats['total']:,})")
    
    # MoE Neck ì„¸ë¶€ ë¶„ì„
    if hasattr(model, 'neck'):
        moe_stats = analyze_moe_neck(model.neck)
        
        print(f"\nğŸ”€ MoE Neck ì„¸ë¶€ ë¶„ì„:")
        print("-" * 50)
        print(f"  ì´ Neck íŒŒë¼ë¯¸í„°: {format_number(moe_stats['total_params']):>12}")
        
        if 'gate_router' in moe_stats['components']:
            gate_params = moe_stats['components']['gate_router']
            gate_ratio = gate_params / moe_stats['total_params'] * 100
            print(f"\n  ğŸ¯ Router (Gate):  {format_number(gate_params):>12} ({gate_ratio:.1f}% of Neck)")
            
            # Gate ì„¸ë¶€ êµ¬ì¡°
            if 'gate_details' in moe_stats['components']:
                details = moe_stats['components']['gate_details']
                print(f"     â”œâ”€ Self-Attention:   {format_number(details.get('self_attention', 0)):>10}")
                print(f"     â”œâ”€ Cross-Attention:  {format_number(details.get('cross_attention', 0)):>10}")
                print(f"     â”œâ”€ Expert Queries:   {format_number(details.get('expert_queries', 0)):>10}")
                print(f"     â””â”€ Gate Projection:  {format_number(details.get('gate_proj', 0)):>10}")
        
        if 'experts' in moe_stats['components']:
            exp_info = moe_stats['components']['experts']
            experts_ratio = exp_info['total_experts'] / moe_stats['total_params'] * 100
            print(f"\n  ğŸ¤– Experts ({exp_info['num_experts']}ê°œ):   {format_number(exp_info['total_experts']):>12} ({experts_ratio:.1f}% of Neck)")
            print(f"     â””â”€ ë‹¨ì¼ Expert:     {format_number(exp_info['single_expert']):>10}")
        
        if 'pos_embed' in moe_stats['components']:
            pos_params = moe_stats['components']['pos_embed']
            pos_ratio = pos_params / moe_stats['total_params'] * 100
            print(f"\n  ğŸ“ Position Embed: {format_number(pos_params):>12} ({pos_ratio:.1f}% of Neck)")
        
        # Top-K í™œì„±í™” ì •ë³´
        if 'top_k_info' in moe_stats:
            info = moe_stats['top_k_info']
            print(f"\n  âš¡ ì‹¤ì œ í™œì„±í™” íŒŒë¼ë¯¸í„° (Expertë§Œ ê³„ì‚°):")
            print(f"     â”œâ”€ Train (top-{info['train_top_k']}): {format_number(exp_info['single_expert'] * info['train_top_k']):>10} ({info['train_activation_ratio']*100:.0f}% experts)")
            print(f"     â””â”€ Eval  (top-{info['eval_top_k']}): {format_number(exp_info['single_expert'] * info['eval_top_k']):>10} ({info['eval_activation_ratio']*100:.0f}% experts)")
            
            # ì „ì²´ ëª¨ë¸ ê¸°ì¤€ ì‹¤ì œ í™œì„±í™” íŒŒë¼ë¯¸í„°
            total_params = param_stats['total']
            router_and_pos = gate_params + pos_params
            active_train = router_and_pos + (exp_info['single_expert'] * info['train_top_k'])
            active_eval = router_and_pos + (exp_info['single_expert'] * info['eval_top_k'])
            
            backbone_params = component_stats.get('backbone', {}).get('total', 0)
            head_params = component_stats.get('head', {}).get('total', 0)
            
            print(f"\n  ğŸ’¡ ì „ì²´ ëª¨ë¸ ê¸°ì¤€ í™œì„±í™” íŒŒë¼ë¯¸í„°:")
            print(f"     â”œâ”€ Backbone:        {format_number(backbone_params):>10}")
            print(f"     â”œâ”€ Neck (í™œì„±í™”):   {format_number(active_train):>10} (Train) / {format_number(active_eval):>10} (Eval)")
            print(f"     â”œâ”€ Head:            {format_number(head_params):>10}")
            print(f"     â”œâ”€ Train í•©ê³„:      {format_number(backbone_params + active_train + head_params):>10}")
            print(f"     â””â”€ Eval  í•©ê³„:      {format_number(backbone_params + active_eval + head_params):>10}")
    
    # ì»´í¬ë„ŒíŠ¸ë³„ FLOPs ë¶„ì„
    analyze_components_flops(model, input_shape)


def main():
    print("ğŸš€ CUB ëª¨ë¸ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("=" * 80)
    
    # CUB ì„¤ì • íŒŒì¼ë“¤
    configs = {
        "CUB Base": "configs/cub/cub_base.py",
        "CUB Incremental": "configs/cub/cub_inc.py"
    }
    
    # CUB ì´ë¯¸ì§€ í¬ê¸° (ì¼ë°˜ì ìœ¼ë¡œ 224x224)
    input_shape = (3, 224, 224)
    
    for config_name, config_path in configs.items():
        if not os.path.exists(config_path):
            print(f"\nâŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            continue
            
        try:
            print(f"\nğŸ”„ {config_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
            print("-" * 40)
            
            # ì„¤ì • íŒŒì¼ ë¡œë“œ
            cfg = Config.fromfile(config_path)
            
            # ëª¨ë¸ ë¹Œë“œ
            model = build_classifier(cfg.model)
            
            # ëª¨ë¸ ë¶„ì„ ì‹¤í–‰
            print_model_analysis(model, config_name, input_shape)
            
        except Exception as e:
            print(f"\nâŒ {config_name} ëª¨ë¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    print("âœ… ëª¨ë¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == '__main__':
    main()
