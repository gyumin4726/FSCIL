import os
import sys
import torch
import torch.nn as nn
from mmcv import Config
from mmcls.models import build_classifier
import numpy as np
from typing import Dict, Any, Tuple

import mmfscil


def count_parameters(model: nn.Module) -> Dict[str, int]:
    """ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    frozen_params = total_params - trainable_params
    
    return {
        'total': total_params,
        'trainable': trainable_params,
        'frozen': frozen_params
    }




def try_thop_flops_component(component: nn.Module, input_shape: Tuple[int, ...], component_name: str) -> Tuple[int, int]:
    """ì»´í¬ë„ŒíŠ¸ë³„ë¡œ thop ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ FLOPsë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    try:
        from thop import profile
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ CUDAë¡œ, ì•„ë‹ˆë©´ CPUë¡œ
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        component = component.to(device)
        component.eval()
        
        dummy_input = torch.randn(1, *input_shape).to(device)
        
        # ETFHeadì˜ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
        if 'ETFHead' in component_name:
            # ETFHeadëŠ” forward ëŒ€ì‹  simple_testë‚˜ ë‹¤ë¥¸ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
            try:
                # ë¨¼ì € ì¼ë°˜ì ì¸ forward ì‹œë„
                flops, params = profile(component, inputs=(dummy_input,), verbose=False)
            except:
                # forwardê°€ ì—†ìœ¼ë©´ íŒŒë¼ë¯¸í„°ë§Œ ê³„ì‚°
                params = sum(p.numel() for p in component.parameters())
                # ETFHeadëŠ” ì£¼ë¡œ Linear layerì´ë¯€ë¡œ ê°„ë‹¨íˆ ì¶”ì •
                if hasattr(component, 'in_channels') and hasattr(component, 'num_classes'):
                    flops = component.in_channels * component.num_classes
                else:
                    flops = 0
                print(f"    ğŸ’¡ ETFHeadëŠ” í‘œì¤€ forwardê°€ ì—†ì–´ ì¶”ì •ê°’ ì‚¬ìš©")
                return int(flops), int(params)
        else:
            # thopì„ ì‚¬ìš©í•˜ì—¬ FLOPsì™€ íŒŒë¼ë¯¸í„° ê³„ì‚°
            flops, params = profile(component, inputs=(dummy_input,), verbose=False)
        
        return int(flops), int(params)
    except ImportError:
        print("ğŸ’¡ thop ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install thop")
        return None, None
    except Exception as e:
        print(f"Warning: {component_name} thop FLOPs ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ìµœì†Œí•œ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ê³„ì‚°
        try:
            params = sum(p.numel() for p in component.parameters())
            return 0, int(params)  # FLOPsëŠ” 0ìœ¼ë¡œ, íŒŒë¼ë¯¸í„°ëŠ” ì‹¤ì œ ê°’
        except:
            return None, None


def estimate_neck_flops_from_structure(
    neck: nn.Module, 
    seq_len: int, 
    train_top_k: int = None, 
    eval_top_k: int = None,
    num_experts: int = None
) -> Dict[str, int]:
    """Neck êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ FLOPsë¥¼ ì¶”ì •í•©ë‹ˆë‹¤."""
    
    result = {
        'neck_train': 0,
        'neck_eval': 0,
        'estimation_method': 'structure_based'
    }
    
    total_flops = 0
    expert_flops = 0
    router_flops = 0
    
    # ê° ì»´í¬ë„ŒíŠ¸ë³„ë¡œ FLOPs ì¶”ì •
    for name, module in neck.named_children():
        module_flops = 0
        
        # Linear layers
        if isinstance(module, nn.Linear):
            # FLOPs = 2 * input_dim * output_dim * batch * seq_len
            # (2ëŠ” ê³±ì…ˆê³¼ ë§ì…ˆ)
            module_flops = 2 * module.in_features * module.out_features * seq_len
        
        # ì„œë¸Œëª¨ë“ˆ ì¬ê·€ì ìœ¼ë¡œ ê³„ì‚°
        for sub_name, sub_module in module.named_modules():
            if isinstance(sub_module, nn.Linear):
                module_flops += 2 * sub_module.in_features * sub_module.out_features * seq_len
            elif isinstance(sub_module, nn.MultiheadAttention):
                # Attention FLOPs = 4 * seq_len * dim * dim + 2 * seq_len^2 * dim
                embed_dim = sub_module.embed_dim
                # Q, K, V projections
                module_flops += 3 * (2 * seq_len * embed_dim * embed_dim)
                # Attention scores: Q @ K^T
                module_flops += 2 * seq_len * seq_len * embed_dim
                # Attention output: Attn @ V
                module_flops += 2 * seq_len * seq_len * embed_dim
                # Output projection
                module_flops += 2 * seq_len * embed_dim * embed_dim
            elif isinstance(sub_module, nn.LayerNorm):
                # LayerNorm FLOPs = 2 * normalized_shape * seq_len
                if hasattr(sub_module, 'normalized_shape'):
                    norm_size = np.prod(sub_module.normalized_shape)
                    module_flops += 2 * norm_size * seq_len
            elif isinstance(sub_module, nn.Conv2d):
                # Conv2D FLOPs = 2 * kernel_h * kernel_w * in_ch * out_ch * out_h * out_w
                k_h, k_w = sub_module.kernel_size if isinstance(sub_module.kernel_size, tuple) else (sub_module.kernel_size, sub_module.kernel_size)
                module_flops += 2 * k_h * k_w * sub_module.in_channels * sub_module.out_channels * seq_len
        
        # Expertì¸ì§€ í™•ì¸ (ModuleListë‚˜ ì´ë¦„ì— 'expert'ê°€ í¬í•¨)
        if 'expert' in name.lower() and isinstance(module, nn.ModuleList):
            # Expert FLOPsëŠ” ë³„ë„ë¡œ ì €ì¥ (í™œì„±í™” ë¹„ìœ¨ ê³„ì‚°ìš©)
            if len(module) > 0:
                single_expert_flops = sum(
                    2 * m.in_features * m.out_features * seq_len 
                    for m in module[0].modules() if isinstance(m, nn.Linear)
                )
                expert_flops = single_expert_flops * len(module)
                module_flops = expert_flops  # ì¼ë‹¨ ì „ì²´ expert flops ì €ì¥
        elif 'gate' in name.lower() or 'router' in name.lower():
            # Router FLOPsëŠ” í•­ìƒ ì‚¬ìš©ë¨
            router_flops = module_flops
        
        total_flops += module_flops
    
    # Position embedding ì²˜ë¦¬
    for param_name, param in neck.named_parameters(recurse=False):
        if 'pos_embed' in param_name:
            # Position embedding addition: seq_len * embed_dim
            total_flops += param.numel()
    
    # MoEì˜ ê²½ìš° í™œì„± expert ë¹„ìœ¨ ê³ ë ¤
    if num_experts and train_top_k and eval_top_k and expert_flops > 0:
        single_expert_flops = expert_flops / num_experts
        
        # Router + í™œì„± experts
        train_active_flops = router_flops + single_expert_flops * train_top_k
        eval_active_flops = router_flops + single_expert_flops * eval_top_k
        
        # ë‚˜ë¨¸ì§€ ì»´í¬ë„ŒíŠ¸ (pos_embed ë“±) ì¶”ê°€
        other_flops = total_flops - expert_flops - router_flops
        
        result['neck_train'] = int(train_active_flops + other_flops)
        result['neck_eval'] = int(eval_active_flops + other_flops)
        result['expert_flops'] = int(single_expert_flops)
        result['router_flops'] = int(router_flops)
    else:
        # MoEê°€ ì•„ë‹Œ ê²½ìš° ëª¨ë“  íŒŒë¼ë¯¸í„° ì‚¬ìš©
        result['neck_train'] = int(total_flops)
        result['neck_eval'] = int(total_flops)
    
    return result


def analyze_moe_flops(neck: nn.Module, input_shape: Tuple[int, ...]) -> Dict[str, int]:
    """MoE Neckì˜ Train/Eval ëª¨ë“œë³„ FLOPsë¥¼ ì¶”ì •í•©ë‹ˆë‹¤ (ì¼ë°˜ì ì¸ ë°©ì‹)."""
    flops_info = {
        'neck_train': 0,
        'neck_eval': 0,
        'estimation_method': 'parameter_based'
    }
    
    # ì…ë ¥ í¬ê¸°ë¡œë¶€í„° feature map í¬ê¸° ì¶”ì •
    C, H, W = input_shape
    seq_len = H * W
    
    # Neckì˜ top_k ì •ë³´ ì°¾ê¸°
    train_top_k = None
    eval_top_k = None
    num_experts = None
    
    for name, module in neck.named_modules():
        if hasattr(module, 'top_k'):
            train_top_k = module.top_k
        if hasattr(module, 'eval_top_k'):
            eval_top_k = module.eval_top_k
        if hasattr(module, 'num_experts'):
            num_experts = module.num_experts
    
    # thopìœ¼ë¡œ ì‹œë„
    try:
        from thop import profile
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        neck_copy = neck.to(device)
        neck_copy.eval()
        
        dummy_input = torch.randn(1, C, H, W).to(device)
        
        # Eval ëª¨ë“œ FLOPs
        with torch.no_grad():
            eval_flops, _ = profile(neck_copy, inputs=(dummy_input,), verbose=False)
        
        flops_info['neck_eval'] = int(eval_flops)
        
        # Train ëª¨ë“œ FLOPs (MoEê°€ ìˆê³  top_kê°€ ë‹¤ë¥¸ ê²½ìš°)
        if train_top_k and eval_top_k and train_top_k != eval_top_k:
            # top_k ë¹„ìœ¨ë¡œ ì¶”ì •
            ratio = train_top_k / eval_top_k if eval_top_k > 0 else 1
            flops_info['neck_train'] = int(eval_flops * ratio)
        else:
            flops_info['neck_train'] = flops_info['neck_eval']
        
        flops_info['estimation_method'] = 'thop'
        
    except Exception as e:
        # thop ì‹¤íŒ¨ ì‹œ íŒŒë¼ë¯¸í„° ê¸°ë°˜ ì¶”ì •
        print(f"  ğŸ’¡ FLOPs ì§ì ‘ ê³„ì‚° ì‹¤íŒ¨, íŒŒë¼ë¯¸í„° ê¸°ë°˜ ì¶”ì • ì‚¬ìš©: {e}")
        
        # ë” ì •í™•í•œ FLOPs ì¶”ì •
        flops_info.update(estimate_neck_flops_from_structure(
            neck, seq_len, train_top_k, eval_top_k, num_experts
        ))
    
    # MoE ì •ë³´ ì¶”ê°€
    if train_top_k is not None:
        flops_info['train_top_k'] = train_top_k
    if eval_top_k is not None:
        flops_info['eval_top_k'] = eval_top_k
    if num_experts is not None:
        flops_info['num_experts'] = num_experts
    
    return flops_info


def analyze_components_flops(model, input_shape: Tuple[int, ...] = (3, 224, 224)):
    """ëª¨ë¸ì˜ ê° ì»´í¬ë„ŒíŠ¸ë³„ë¡œ FLOPsë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    print(f"\nâš¡ ì»´í¬ë„ŒíŠ¸ë³„ FLOPs ë¶„ì„ (ì…ë ¥ í¬ê¸°: {input_shape})")
    print("=" * 60)
    
    total_flops = 0
    total_params = 0
    neck_train_flops = 0
    neck_eval_flops = 0
    
    # Backbone ë¶„ì„ (FLOPs ê³„ì‚°ì€ ìƒëµ, Neck ì…ë ¥ í¬ê¸°ë§Œ í™•ì¸)
    backbone_output_shape = (1024, 7, 7)  # ê¸°ë³¸ê°’
    
    if hasattr(model, 'backbone') and model.backbone is not None:
        print(f"\nğŸ”§ Backbone: {type(model.backbone).__name__}")
        print("-" * 40)
        
        actual_params = sum(p.numel() for p in model.backbone.parameters())
        print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:    {format_number(actual_params):>12}")
        print(f"  ğŸ’¡ FLOPs ê³„ì‚°ì€ ìƒëµí•©ë‹ˆë‹¤ (ë³µì¡í•œ êµ¬ì¡°)")
        total_params += actual_params
        
        # Backbone ì¶œë ¥ í¬ê¸° ìë™ ê°ì§€ (Neck ì…ë ¥ìš©)
        try:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            with torch.no_grad():
                dummy_input = torch.randn(1, *input_shape).to(device)
                model.backbone.eval()
                backbone_out = model.backbone(dummy_input)
                if isinstance(backbone_out, tuple):
                    backbone_out = backbone_out[-1]  # ë§ˆì§€ë§‰ feature map ì‚¬ìš©
                _, C, H, W = backbone_out.shape
                backbone_output_shape = (C, H, W)
                print(f"  âœ… Neck ì…ë ¥ í¬ê¸°: {backbone_output_shape}")
        except Exception as e:
            # ì‹¤íŒ¨í•˜ë©´ neckì˜ in_channels ì‚¬ìš©
            if hasattr(model, 'neck') and hasattr(model.neck, 'in_channels'):
                backbone_output_shape = (model.neck.in_channels, 7, 7)
                print(f"  ğŸ’¡ Neck ì…ë ¥ í¬ê¸° (ì¶”ì •): {backbone_output_shape}")
            else:
                print(f"  âš ï¸ Neck ì…ë ¥ í¬ê¸° (ê¸°ë³¸ê°’): {backbone_output_shape}")
    
    # Neck ë¶„ì„
    if hasattr(model, 'neck') and model.neck is not None:
        print(f"\nğŸ”— Neck: {type(model.neck).__name__}")
        print("-" * 40)
        try:
            actual_params = sum(p.numel() for p in model.neck.parameters())
            print(f"  ğŸ”¢ íŒŒë¼ë¯¸í„°:         {format_number(actual_params):>12}")
            
            # FLOPs ë¶„ì„
            moe_flops = analyze_moe_flops(model.neck, backbone_output_shape)
            
            print(f"  ğŸ“Š ì¶”ì • ë°©ë²•:        {moe_flops.get('estimation_method', 'unknown')}")
            print(f"  âš¡ Train FLOPs:      {format_number(moe_flops['neck_train']):>12}")
            print(f"  âš¡ Eval FLOPs:       {format_number(moe_flops['neck_eval']):>12}")
            
            # ì„¸ë¶€ FLOPs ì •ë³´ (structure_based ì¶”ì •ì¸ ê²½ìš°)
            if moe_flops.get('estimation_method') == 'structure_based':
                if 'router_flops' in moe_flops:
                    print(f"\n  ğŸ“Š ì„¸ë¶€ FLOPs:")
                    print(f"     â”œâ”€ Router:          {format_number(moe_flops['router_flops']):>12}")
                    if 'expert_flops' in moe_flops:
                        print(f"     â””â”€ Single Expert:   {format_number(moe_flops['expert_flops']):>12}")
            
            # MoE ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶œë ¥
            if 'train_top_k' in moe_flops or 'eval_top_k' in moe_flops:
                print(f"\n  ğŸ’¡ MoE ì„¤ì •:")
                if 'num_experts' in moe_flops:
                    print(f"     â”œâ”€ Experts: {moe_flops['num_experts']}")
                if 'train_top_k' in moe_flops:
                    print(f"     â”œâ”€ Train top-k: {moe_flops['train_top_k']}")
                if 'eval_top_k' in moe_flops:
                    print(f"     â””â”€ Eval top-k: {moe_flops['eval_top_k']}")
            
            neck_train_flops = moe_flops['neck_train']
            neck_eval_flops = moe_flops['neck_eval']
            total_params += actual_params
            
        except Exception as e:
            print(f"  âŒ FLOPs ê³„ì‚° ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    # Head ë¶„ì„ (ETFHeadëŠ” íŒŒë¼ë¯¸í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ìƒëµ)
    # ETFHeadëŠ” ê³ ì •ëœ ETF classifierë¡œ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ê°€ ì—†ìŒ

    if neck_train_flops > 0 or neck_eval_flops > 0:
        print(f"\nğŸ† Neck FLOPs ìš”ì•½")
        print("=" * 60)
        
        print(f"  ğŸ“Š Train FLOPs (Neck): {format_number(neck_train_flops):>12}")
        print(f"  ğŸ“Š Eval FLOPs (Neck):  {format_number(neck_eval_flops):>12}")
        
        if neck_train_flops != neck_eval_flops and neck_eval_flops > 0:
            flops_reduction = neck_train_flops - neck_eval_flops
            reduction_ratio = (flops_reduction / neck_train_flops * 100) if neck_train_flops > 0 else 0
            print(f"  ğŸ’¡ Eval FLOPs ì ˆê°:   {format_number(flops_reduction):>12} ({reduction_ratio:.1f}% ê°ì†Œ)")
        
        print(f"  ğŸ”¢ ì´ íŒŒë¼ë¯¸í„°:        {format_number(total_params):>12}")
    
    return total_flops, total_params


def format_number(num: int) -> str:
    """ìˆ«ìë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·í•©ë‹ˆë‹¤."""
    if num >= 1e12:
        return f"{num/1e12:.2f}T"
    elif num >= 1e9:
        return f"{num/1e9:.2f}G"
    elif num >= 1e6:
        return f"{num/1e6:.2f}M"
    elif num >= 1e3:
        return f"{num/1e3:.2f}K"
    else:
        return str(num)


def analyze_model_components(model: nn.Module) -> Dict[str, Dict[str, int]]:
    """ëª¨ë¸ì˜ ê° ì»´í¬ë„ŒíŠ¸ë³„ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    component_stats = {}
    
    for name, module in model.named_children():
        params = count_parameters(module)
        component_stats[name] = params
    
    return component_stats


def get_module_tree(module: nn.Module, max_depth: int = 5, current_depth: int = 0) -> Dict[str, Any]:
    """ëª¨ë“ˆì„ ì¬ê·€ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if current_depth >= max_depth:
        return None
    
    # ì§ì† íŒŒë¼ë¯¸í„° (ì„œë¸Œëª¨ë“ˆ ì œì™¸)
    direct_params = sum(p.numel() for p in module.parameters(recurse=False))
    total_params = sum(p.numel() for p in module.parameters())
    
    result = {
        'total_params': total_params,
        'direct_params': direct_params,
        'type': type(module).__name__,
        'children': {}
    }
    
    # ì§ì† ì„œë¸Œëª¨ë“ˆ ë¶„ì„
    for name, child_module in module.named_children():
        child_params = sum(p.numel() for p in child_module.parameters())
        if child_params > 0:
            child_tree = get_module_tree(child_module, max_depth, current_depth + 1)
            if child_tree:
                result['children'][name] = child_tree
    
    return result


def print_module_tree(tree: Dict[str, Any], name: str = "root", indent: int = 0, is_last: bool = True, prefix: str = ""):
    """ëª¨ë“ˆ íŠ¸ë¦¬ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if tree is None:
        return
    
    # íŠ¸ë¦¬ êµ¬ì¡° ë¬¸ì
    if indent == 0:
        connector = ""
        next_prefix = ""
    else:
        connector = "â””â”€ " if is_last else "â”œâ”€ "
        next_prefix = prefix + ("   " if is_last else "â”‚  ")
    
    # í˜„ì¬ ë…¸ë“œ ì¶œë ¥
    total = tree['total_params']
    direct = tree['direct_params']
    type_name = tree['type']
    
    if direct > 0:
        print(f"{prefix}{connector}{name:30} {format_number(total):>12} (ì§ì ‘: {format_number(direct):>10}) [{type_name}]")
    else:
        print(f"{prefix}{connector}{name:30} {format_number(total):>12} [{type_name}]")
    
    # ìì‹ ë…¸ë“œ ì¬ê·€ ì¶œë ¥
    children = list(tree['children'].items())
    for i, (child_name, child_tree) in enumerate(children):
        is_last_child = (i == len(children) - 1)
        print_module_tree(child_tree, child_name, indent + 1, is_last_child, next_prefix)


def analyze_moe_neck(neck: nn.Module) -> Dict[str, Any]:
    """MoE Neckì˜ ì„¸ë¶€ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (ì¬ê·€ì ìœ¼ë¡œ ìµœì†Œ ë‹¨ìœ„ê¹Œì§€)."""
    stats = {
        'total_params': sum(p.numel() for p in neck.parameters()),
        'tree': get_module_tree(neck, max_depth=5)
    }
    
    # MoE ê´€ë ¨ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    moe_info = {}
    for name, module in neck.named_modules():
        if hasattr(module, 'top_k'):
            moe_info['train_top_k'] = module.top_k
        if hasattr(module, 'eval_top_k'):
            moe_info['eval_top_k'] = module.eval_top_k
        if hasattr(module, 'num_experts'):
            moe_info['num_experts'] = module.num_experts
    
    if moe_info:
        stats['moe_info'] = moe_info
    
    return stats


def print_model_analysis(model: nn.Module, config_name: str, input_shape: Tuple[int, ...] = (3, 224, 224)):
    """ëª¨ë¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("=" * 80)
    print(f"ğŸ” CUB ëª¨ë¸ ë¶„ì„ ê²°ê³¼ - {config_name}")
    print("=" * 80)
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    param_stats = count_parameters(model)
    print(f"\nğŸ“Š íŒŒë¼ë¯¸í„° í†µê³„:")
    print("-" * 50)
    print(f"  ì „ì²´ íŒŒë¼ë¯¸í„°:     {format_number(param_stats['total']):>12} ({param_stats['total']:,})")
    print(f"  í›ˆë ¨ ê°€ëŠ¥:        {format_number(param_stats['trainable']):>12} ({param_stats['trainable']:,})")
    print(f"  ê³ ì •ë¨:          {format_number(param_stats['frozen']):>12} ({param_stats['frozen']:,})")
    
    # ì»´í¬ë„ŒíŠ¸ë³„ ë¶„ì„
    print(f"\nğŸ§© ì»´í¬ë„ŒíŠ¸ë³„ íŒŒë¼ë¯¸í„°:")
    print("-" * 50)
    component_stats = analyze_model_components(model)
    for comp_name, stats in component_stats.items():
        total_str = f"{format_number(stats['total']):>12}"
        trainable_str = f"{format_number(stats['trainable']):>12}"
        frozen_str = f"{format_number(stats['frozen']):>12}"
        print(f"  {comp_name:12}: {total_str} (í›ˆë ¨: {trainable_str} / ê³ ì •: {frozen_str})")
    
    # MoE Neck ì„¸ë¶€ ë¶„ì„
    if hasattr(model, 'neck') and model.neck is not None:
        moe_stats = analyze_moe_neck(model.neck)
        
        print(f"\nğŸ”€ Neck ì„¸ë¶€ ë¶„ì„ (ì¬ê·€ íŠ¸ë¦¬ êµ¬ì¡°):")
        print("-" * 80)
        print(f"  ì´ Neck íŒŒë¼ë¯¸í„°: {format_number(moe_stats['total_params']):>12}\n")
        
        # íŠ¸ë¦¬ êµ¬ì¡° ì¶œë ¥
        if 'tree' in moe_stats and moe_stats['tree']:
            print(f"  ğŸ“¦ ëª¨ë“ˆ ê³„ì¸µ êµ¬ì¡°:")
            print()
            # Neck ìì²´ ì¶œë ¥
            tree = moe_stats['tree']
            print(f"  Neck                           {format_number(tree['total_params']):>12} [{tree['type']}]")
            # ìì‹ë“¤ ì¶œë ¥
            children = list(tree['children'].items())
            for i, (child_name, child_tree) in enumerate(children):
                is_last = (i == len(children) - 1)
                print_module_tree(child_tree, child_name, indent=1, is_last=is_last, prefix="  ")
        
        # MoE ì •ë³´ ì¶œë ¥ (ìˆëŠ” ê²½ìš°)
        if 'moe_info' in moe_stats:
            info = moe_stats['moe_info']
            print(f"\n  âš¡ MoE ì„¤ì •:")
            if 'num_experts' in info:
                print(f"     â”œâ”€ Expert ê°œìˆ˜:     {info['num_experts']}")
            if 'train_top_k' in info:
                print(f"     â”œâ”€ Train Top-K:     {info['train_top_k']}")
            if 'eval_top_k' in info:
                print(f"     â””â”€ Eval Top-K:      {info['eval_top_k']}")
            
            # í™œì„±í™” ë¹„ìœ¨ ê³„ì‚° (ê°€ëŠ¥í•œ ê²½ìš°)
            if all(k in info for k in ['num_experts', 'train_top_k', 'eval_top_k']):
                train_ratio = info['train_top_k'] / info['num_experts'] * 100
                eval_ratio = info['eval_top_k'] / info['num_experts'] * 100
                print(f"\n  ğŸ’¡ Expert í™œì„±í™” ë¹„ìœ¨:")
                print(f"     â”œâ”€ Train: {train_ratio:.1f}% ({info['train_top_k']}/{info['num_experts']})")
                print(f"     â””â”€ Eval:  {eval_ratio:.1f}% ({info['eval_top_k']}/{info['num_experts']})")
    
    # ì»´í¬ë„ŒíŠ¸ë³„ FLOPs ë¶„ì„
    analyze_components_flops(model, input_shape)


def main():
    print("ğŸš€ CUB ëª¨ë¸ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("=" * 80)
    
    # CUB ì„¤ì • íŒŒì¼ë“¤
    configs = {
        "CUB Base": "configs/cub/cub_base.py",
        "CUB Incremental": "configs/cub/cub_inc.py"
    }
    
    # CUB ì´ë¯¸ì§€ í¬ê¸° (ì¼ë°˜ì ìœ¼ë¡œ 224x224)
    input_shape = (3, 224, 224)
    
    for config_name, config_path in configs.items():
        if not os.path.exists(config_path):
            print(f"\nâŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            continue
            
        try:
            print(f"\nğŸ”„ {config_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
            print("-" * 40)
            
            # ì„¤ì • íŒŒì¼ ë¡œë“œ
            cfg = Config.fromfile(config_path)
            
            # ëª¨ë¸ ë¹Œë“œ
            model = build_classifier(cfg.model)
            
            # ëª¨ë¸ ë¶„ì„ ì‹¤í–‰
            print_model_analysis(model, config_name, input_shape)
            
        except Exception as e:
            print(f"\nâŒ {config_name} ëª¨ë¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    print("âœ… ëª¨ë¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == '__main__':
    main()
